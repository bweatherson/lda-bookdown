```{r t62a}
jjj <- 62
source('topic_comments/topic_summary_data.R') # Get data
```

```{r t62b, fig.cap=paste0(fcap(the_categories$sub_lower[jjj]),"."),  fig.alt = alt_text, fig.height= 5.2}
source('topic_comments/topic_summary_overall_graph.R')
```

```{r t62c, fig.cap=paste(fcap(the_categories$sub_lower[jjj]), "articles in each journal."), fig.alt = alt_text_journals}
source('topic_comments/topic_summary_facet_graph.R')
```

```{r t62d}
source('topic_comments/topic_summary_char_art.R') # Create table of all articles in topic
temp_dt
```

```{r t62e}
source('topic_comments/topic_summary_high_cites.R') # Generate table of highly cited articles. 
 # Have to do this at same time as previous script or a weird caching error occurs.
if(is_high_cites == 1){high_table} # Conditional because not all topics have high cites
cat("\n

**Comments**
	\n")
```

Given how big a topic this was when I was a graduate student, I was very surprised that it wasn't bigger than it turned out to be. But a look at the overall graph explains why I got this wrong. The high water mark for this topic was from about 1985â€“1995. When I was in graduate school, it really was all over the journals that we were reading. We couldn't have predicted that it would fall from nearly 2 percent of the articles to under 1 percent.

One of the upsides of having a computer model analyze the data rather than going with one's own impressions is that it reduces the impact of having an idiosyncratic set of experiences in cases like this one.